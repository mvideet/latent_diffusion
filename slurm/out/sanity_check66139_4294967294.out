ðŸ§ª Starting sanity checks for latent injection training pipeline...
Device: cuda
==================================================
Testing LatentEncoder...
âœ“ LatentEncoder test passed! Output shape: torch.Size([4, 256])
  Latent range: [-0.080, 0.075]
==================================================
Testing forward process...
âœ“ Forward process test passed!
  Input shape: torch.Size([4, 128])
  Masked tokens: 181/512 (35.4%)
  P mask: tensor([[0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590, 0.3590,
         0.3590, 0.3590],
        [0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994, 0.2994,
         0.2994, 0.2994],
        [0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300, 0.3300,
         0.3300, 0.3300],
        [0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976, 0.3976,
         0.3976, 0.3976]], device='cuda:0')
  Noisy batch: tensor([[ 38092,   4207,  49443,   5973, 126336,  14694,  17249,  18429,  32742,
          12194, 126336,  43770,  10845,  21019, 126336, 126336,   9935, 126336,
          10688,   6804, 126336,  17581,  24199,  36415,  28400,  26049, 126336,
         126336, 126336,  42062,   3625,  35019,  31598,  36385,   9641,   4001,
         126336,  37860, 126336, 126336,  36851,  29181, 126336,   5125,  21928,
         126336,  46649, 126336, 126336,  46492,  25895,  46008, 126336, 126336,
         126336, 126336, 126336,  15389,  29132,  41477,  25518,  16467, 126336,
         126336,   7036,  14828,  19767,  31409, 126336,  22293, 126336, 126336,
          12841,  42474,  42442,   8329, 126336,  10539, 126336,  16419,   1375,
          48092, 126336,  18132,  45369,  13781, 126336, 126336,   8295, 126336,
          46470,  44877,  40438, 126336,  21453, 126336,  14442,  37582, 126336,
          19870,  22101, 126336,  35744,   7048,  15635, 126336, 126336,  16675,
         126336,  29856, 126336,  22883,  24205,  38095,  22285, 126336, 126336,
          13190,  47887, 126336, 126336,  43346,  27876,  23520,  20984,  42504,
          42149,  19052],
        [ 49972,  35252,   9994,   9904,  17295,   4261, 126336,  49118,  45069,
          36595, 126336, 126336,   2921,  49584,  43784,  15070,  13950,   7695,
         126336,  19832,  18470,  49298, 126336,   4191,  46589,  24083, 126336,
         126336,  20568, 126336, 126336,  35668,  27638,   4441, 126336,  17611,
         126336, 126336,  10061,    221,  45950,  25788,  23762,  16939,  44531,
          35884,   2944, 126336,  40054, 126336,  12937,  32220,  45818, 126336,
          32584,  43735,  42620,  29932,  10567,  40330, 126336,  46885,   8275,
          22006,  22798,   3273,  46453, 126336,   7277,  27151,   6418, 126336,
          17226,  41604, 126336,   1787, 126336,  15717, 126336,  21922,  28710,
          10766, 126336, 126336,  26558,  39346, 126336,    102,  16982,   9661,
          34736, 126336, 126336,  39364,  16946, 126336, 126336,  32488,  45310,
          47301,  19456, 126336,  39000,  21967,  26290, 126336,  10932,   1525,
          38051,  30990,  12356,  41899,  14006,  23510,  20268, 126336,   3472,
         126336,  40013, 126336,  10214,   3702,  40560, 126336,  10944, 126336,
          14801,  15454],
        [ 48374, 126336,  43717,  37129,   7838,  12992, 126336, 126336,  26661,
          12740,  43050, 126336,  16254, 126336, 126336, 126336,  42305,  17784,
         126336, 126336,  26507,   4131,  27597,  48604,  18051, 126336,  41549,
          18890, 126336,  34997, 126336,  23296,  19799,  24768,  48789,  46678,
          28473, 126336,  18596, 126336,  47353, 126336, 126336,  44767, 126336,
           4966,  16858, 126336,  31470,  30474,  11849,  29298, 126336,  48127,
         126336,   3069,   2573,  20593, 126336,  43171, 126336, 126336, 126336,
           5180, 126336,  40219,  47267, 126336, 126336, 126336, 126336, 126336,
          27139,  25592, 126336,  43327,  36906, 126336, 126336,   8182,   8266,
          23876,  33714,  38377, 126336,   1868,  28731,  11356, 126336,   2419,
          44145, 126336,  23433, 126336, 126336,  20122,  31560, 126336,  40945,
          41220,  37011, 126336,  10083, 126336,  21238, 126336,  12456,  44149,
           9156, 126336, 126336, 126336, 126336,  42888,  12209,  26285, 126336,
          28862,  26185,  35862,   3624, 126336,  46179,  48784,  28884, 126336,
          29646,   7025],
        [ 48676, 126336,    923,  21841, 126336,  32019, 126336,  49077,  30371,
          10167, 126336, 126336, 126336,  27664,  32235, 126336,   2025, 126336,
         126336,  48060,  36145, 126336, 126336, 126336,  36323,  23762,  29194,
         126336,  26193, 126336,  27834,   3502, 126336, 126336, 126336, 126336,
          45851,  30736,  31647,  39568,  13492, 126336, 126336,  10824,  18310,
           3302,  36494, 126336,  13543, 126336, 126336, 126336,  14603, 126336,
         126336, 126336,  20137, 126336, 126336, 126336, 126336,  49833,  34376,
         126336,  32370, 126336,  49810,  39520, 126336,  42898,  49066,  24964,
           5697,  44157,   2625, 126336,   1784,  22514,  16040,  43263, 126336,
            887,   2334,    178,  17445, 126336,  21225,  37095,  41064, 126336,
         126336,  27378,  17714, 126336, 126336, 126336,   5113, 126336,  16002,
         126336,    233,  31988, 126336,  46517, 126336,   2489,  15267,  37846,
         126336,  18177,  26471, 126336,   8772,   6597,  41259,    114, 126336,
          36356,   3612,  20519,   2853,   5471, 126336, 126336, 126336,  35014,
         126336,   6438]], device='cuda:0')
  Masked indices: tensor([[False, False, False, False,  True, False, False, False, False, False,
          True, False, False, False,  True,  True, False,  True, False, False,
          True, False, False, False, False, False,  True,  True,  True, False,
         False, False, False, False, False, False,  True, False,  True,  True,
         False, False,  True, False, False,  True, False,  True,  True, False,
         False, False,  True,  True,  True,  True,  True, False, False, False,
         False, False,  True,  True, False, False, False, False,  True, False,
          True,  True, False, False, False, False,  True, False,  True, False,
         False, False,  True, False, False, False,  True,  True, False,  True,
         False, False, False,  True, False,  True, False, False,  True, False,
         False,  True, False, False, False,  True,  True, False,  True, False,
          True, False, False, False, False,  True,  True, False, False,  True,
          True, False, False, False, False, False, False, False],
        [False, False, False, False, False, False,  True, False, False, False,
          True,  True, False, False, False, False, False, False,  True, False,
         False, False,  True, False, False, False,  True,  True, False,  True,
          True, False, False, False,  True, False,  True,  True, False, False,
         False, False, False, False, False, False, False,  True, False,  True,
         False, False, False,  True, False, False, False, False, False, False,
          True, False, False, False, False, False, False,  True, False, False,
         False,  True, False, False,  True, False,  True, False,  True, False,
         False, False,  True,  True, False, False,  True, False, False, False,
         False,  True,  True, False, False,  True,  True, False, False, False,
         False,  True, False, False, False,  True, False, False, False, False,
         False, False, False, False, False,  True, False,  True, False,  True,
         False, False, False,  True, False,  True, False, False],
        [False,  True, False, False, False, False,  True,  True, False, False,
         False,  True, False,  True,  True,  True, False, False,  True,  True,
         False, False, False, False, False,  True, False, False,  True, False,
          True, False, False, False, False, False, False,  True, False,  True,
         False,  True,  True, False,  True, False, False,  True, False, False,
         False, False,  True, False,  True, False, False, False,  True, False,
          True,  True,  True, False,  True, False, False,  True,  True,  True,
          True,  True, False, False,  True, False, False,  True,  True, False,
         False, False, False, False,  True, False, False, False,  True, False,
         False,  True, False,  True,  True, False, False,  True, False, False,
         False,  True, False,  True, False,  True, False, False, False,  True,
          True,  True,  True, False, False, False,  True, False, False, False,
         False,  True, False, False, False,  True, False, False],
        [False,  True, False, False,  True, False,  True, False, False, False,
          True,  True,  True, False, False,  True, False,  True,  True, False,
         False,  True,  True,  True, False, False, False,  True, False,  True,
         False, False,  True,  True,  True,  True, False, False, False, False,
         False,  True,  True, False, False, False, False,  True, False,  True,
          True,  True, False,  True,  True,  True, False,  True,  True,  True,
          True, False, False,  True, False,  True, False, False,  True, False,
         False, False, False, False, False,  True, False, False, False, False,
          True, False, False, False, False,  True, False, False, False,  True,
          True, False, False,  True,  True,  True, False,  True, False,  True,
         False, False,  True, False,  True, False, False, False,  True, False,
         False,  True, False, False, False, False,  True, False, False, False,
         False, False,  True,  True,  True, False,  True, False]],
       device='cuda:0')
==================================================
Testing ReasoningLatentGenerator...
Loading thinker model...
âš  ReasoningLatentGenerator test failed: Incorrect path_or_model_id: './llada-8b'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
  This might be due to missing model files. Continuing with other tests...
==================================================
Testing FiLM-enabled LLaDA model...
âš  FiLM model test failed: Incorrect path_or_model_id: './llada-8b'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
  This might be due to missing model files. Continuing with other tests...
==================================================
Testing full training pipeline...
Loading LLaDA model with FiLM adapters...
âš  Full pipeline test failed: Incorrect path_or_model_id: './llada-8b'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
  This might be due to missing model files. Check the individual component tests above.
==================================================
Testing gradient flow...
Loading LLaDA model with FiLM adapters...
âš  Gradient flow test failed: Incorrect path_or_model_id: './llada-8b'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
==================================================
ðŸŽ‰ Sanity checks completed!

If all tests passed (âœ“), your training pipeline is ready to use.
If some tests failed (âš ), check that:
  1. Model files exist in ./llada-8b/ and ./thinker/
  2. All dependencies are installed
  3. You have sufficient GPU memory
